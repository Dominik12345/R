kNumberOfRandomsteps <- 100
# DEFINE A TRUE SYSTEM -----------------------
# state evolution in time
State1True <- function(t) {
return( 3 * t )
}
State2True <- function(t) {
return( 5 * t**2 )
}
# define outputmatrix
observation.matrix <- matrix(0,  nrow = kDimensionOfStatespace, ncol = kDimensionOfObservationspace )
observation.matrix[1,1] <- 1
observation.matrix[2,2] <- 1
# define timesequence
time <- seq( kTInitial, kTFinal, length.out = kNumberOfTimesteps)
#----------------------------------------------
# DEFINE AN UNFIT SYSTEM ---------------------
# w is kDimensionOfStatespace x number of functions
# define the set of possibe functions
VectorOfFunctions <- function(t) {
return(c(t, t**2, t**3))
}
StateUnfit <- function(w,t) {
return( w %*% VectorOfFunctions(t) )
}
ObservationUnfit <- function(w,t) {
output <- matrix(0, ncol = kDimensionOfObservationspace, nrow = length(t))
for (i in 1:length(t)) {
output[i,] <- observation.matrix %*% StateUnfit(w,t[i])
}
return(output)
}
#----------------------------------------------
# CREATE MEASURED DATA -----------------------
noise.state1.true = runif( kNumberOfTimesteps, -kNoiseAmplitude, kNoiseAmplitude)
noise.state2.true = runif( kNumberOfTimesteps, -kNoiseAmplitude, kNoiseAmplitude)
# evolution of states in time
state1.true <- sapply(time, State1True)
state2.true <- sapply(time, State2True)
# compute observation = (time, y1, y2, ...)
observation <- matrix(0, ncol = kDimensionOfObservationspace +1 , nrow = kNumberOfTimesteps)
for (i in 1:kNumberOfTimesteps) {
observation[i,] <-c(time[i], observation.matrix %*% c(state1.true[i], state2.true[i]) )
}
colnames.temp <- c("t" ,"y1", "y2")
dataframe.true <- as.data.frame(observation)
colnames(dataframe.true) <- colnames.temp
head(dataframe.true)
#----------------------------------------------
# DEFINE COST FUNCTIONAL --------------------
Regularization <- function(w) {
lasso <- 0
ridge <- 0
for (i in 1:length(w)) {
lasso = lasso + abs(w[i])
ridge = ridge + abs(w[i])**2
}
lasso = kAlpha1 * lasso
ridge = 1./2. * kAlpha2 * ridge
}
TotalCost <- function(w, data) {
cost.temp <- 0
for (i in 1:kNumberOfTimesteps) {
cost.temp = cost.temp + (ObservationUnfit(w,data[,"t"])[i,1]-data[i,"y1"] )**2 +
(ObservationUnfit(w,data[,"t"])[i,2] - data[i,"y2"])**2 + Regularization(w)
}
return( cost.temp )
}
#----------------------------------------------
# Finde optimal w by randomly varying w
# this should work since Regularization(w) is convex
w.initial <- matrix(0, nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) ) )
Optimize <- function(w.initial, data) {
#initial cost
cost.initial <- TotalCost(w.initial, data)
#define Algorithm to find an appropriate w
w.process <- w.initial
cost.process <- cost.initial
for (l in 1:length(w.process)) {
for (i in 1:kNumberOfRandomsteps) {
dw = matrix(0, nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) ) )
dw[l] <- runif(1,-1,1)
if(TotalCost(w.process + dw, data) < cost.process) {
w.process = w.process + dw
cost.process = TotalCost(w.process,data)
}
}
}
print("w Matrix")
print(w.process)
print("costs")
print(cost.process)
return(w.process)
}
w.test <- Optimize(w.initial, dataframe.true)
#Einfaches Beispiel zur lasso und ridge Regularisierung
# DEFINE SOME CONSTANTS
kDimensionOfStatespace <- 2
kDimensionOfObservationspace <-2
# time interval
kTInitial <- 0
kTFinal   <- 10
kNumberOfTimesteps <- 100
# regularisation parameters
# 1 = lasso, 2 = ridge
kAlpha1 <- 2.0
kAlpha2 <- 1.0
# noise amplitude
kNoiseAmplitude <- 0.1
kNumberOfRandomsteps <- 100
# DEFINE A TRUE SYSTEM -----------------------
# state evolution in time
State1True <- function(t) {
return( 3 * t )
}
State2True <- function(t) {
return( 5 * t**2 )
}
# define outputmatrix
observation.matrix <- matrix(0,  nrow = kDimensionOfStatespace, ncol = kDimensionOfObservationspace )
observation.matrix[1,1] <- 1
observation.matrix[2,2] <- 1
# define timesequence
time <- seq( kTInitial, kTFinal, length.out = kNumberOfTimesteps)
#----------------------------------------------
# DEFINE AN UNFIT SYSTEM ---------------------
# w is kDimensionOfStatespace x number of functions
# define the set of possibe functions
VectorOfFunctions <- function(t) {
return(c(t, t**2, t**3))
}
StateUnfit <- function(w,t) {
return( w %*% VectorOfFunctions(t) )
}
ObservationUnfit <- function(w,t) {
output <- matrix(0, ncol = kDimensionOfObservationspace, nrow = length(t))
for (i in 1:length(t)) {
output[i,] <- observation.matrix %*% StateUnfit(w,t[i])
}
return(output)
}
#----------------------------------------------
# CREATE MEASURED DATA -----------------------
noise.state1.true = runif( kNumberOfTimesteps, -kNoiseAmplitude, kNoiseAmplitude)
noise.state2.true = runif( kNumberOfTimesteps, -kNoiseAmplitude, kNoiseAmplitude)
# evolution of states in time
state1.true <- sapply(time, State1True)
state2.true <- sapply(time, State2True)
# compute observation = (time, y1, y2, ...)
observation <- matrix(0, ncol = kDimensionOfObservationspace +1 , nrow = kNumberOfTimesteps)
for (i in 1:kNumberOfTimesteps) {
observation[i,] <-c(time[i], observation.matrix %*% c(state1.true[i], state2.true[i]) )
}
colnames.temp <- c("t" ,"y1", "y2")
dataframe.true <- as.data.frame(observation)
colnames(dataframe.true) <- colnames.temp
head(dataframe.true)
#----------------------------------------------
# DEFINE COST FUNCTIONAL --------------------
Regularization <- function(w) {
lasso <- 0
ridge <- 0
for (i in 1:length(w)) {
lasso = lasso + abs(w[i])
ridge = ridge + abs(w[i])**2
}
lasso = kAlpha1 * lasso
ridge = 1./2. * kAlpha2 * ridge
}
TotalCost <- function(w, data) {
cost.temp <- 0
for (i in 1:kNumberOfTimesteps) {
cost.temp = cost.temp + (ObservationUnfit(w,data[,"t"])[i,1]-data[i,"y1"] )**2 +
(ObservationUnfit(w,data[,"t"])[i,2] - data[i,"y2"])**2 + Regularization(w)
}
return( cost.temp )
}
#----------------------------------------------
# Finde optimal w by randomly varying w
# this should work since Regularization(w) is convex
w.initial <- matrix(0, nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) ) )
Optimize <- function(w.initial, data) {
#initial cost
cost.initial <- TotalCost(w.initial, data)
#define Algorithm to find an appropriate w
w.process <- w.initial
cost.process <- cost.initial
for (i in 1:kNumberOfRandomsteps) {
for (l in 1:length(w.process)) {
dw = matrix(0, nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) ) )
dw[l] <- runif(1,-1,1)
if(TotalCost(w.process + dw, data) < cost.process) {
w.process = w.process + dw
cost.process = TotalCost(w.process,data)
}
}
}
print("w Matrix")
print(w.process)
print("costs")
print(cost.process)
return(w.process)
}
w.test <- Optimize(w.initial, dataframe.true)
temp
temp <- matrix(0,3,2)
temp
temp <- runif(6,0,1)
temp
temp <- as.matrix(runif(6,0,1), 3,2)
temp
temp <- matrix(runif(6,0,1),3,2)
temp
#Einfaches Beispiel zur lasso und ridge Regularisierung
# DEFINE SOME CONSTANTS
kDimensionOfStatespace <- 2
kDimensionOfObservationspace <-2
# time interval
kTInitial <- 0
kTFinal   <- 10
kNumberOfTimesteps <- 100
# regularisation parameters
# 1 = lasso, 2 = ridge
kAlpha1 <- 2.0
kAlpha2 <- 1.0
# noise amplitude
kNoiseAmplitude <- 0.1
kNumberOfRandomsteps <- 100
# DEFINE A TRUE SYSTEM -----------------------
# state evolution in time
State1True <- function(t) {
return( 3 * t )
}
State2True <- function(t) {
return( 5 * t**2 )
}
# define outputmatrix
observation.matrix <- matrix(0,  nrow = kDimensionOfStatespace, ncol = kDimensionOfObservationspace )
observation.matrix[1,1] <- 1
observation.matrix[2,2] <- 1
# define timesequence
time <- seq( kTInitial, kTFinal, length.out = kNumberOfTimesteps)
#----------------------------------------------
# DEFINE AN UNFIT SYSTEM ---------------------
# w is kDimensionOfStatespace x number of functions
# define the set of possibe functions
VectorOfFunctions <- function(t) {
return(c(t, t**2, t**3))
}
StateUnfit <- function(w,t) {
return( w %*% VectorOfFunctions(t) )
}
ObservationUnfit <- function(w,t) {
output <- matrix(0, ncol = kDimensionOfObservationspace, nrow = length(t))
for (i in 1:length(t)) {
output[i,] <- observation.matrix %*% StateUnfit(w,t[i])
}
return(output)
}
#----------------------------------------------
# CREATE MEASURED DATA -----------------------
noise.state1.true = runif( kNumberOfTimesteps, -kNoiseAmplitude, kNoiseAmplitude)
noise.state2.true = runif( kNumberOfTimesteps, -kNoiseAmplitude, kNoiseAmplitude)
# evolution of states in time
state1.true <- sapply(time, State1True)
state2.true <- sapply(time, State2True)
# compute observation = (time, y1, y2, ...)
observation <- matrix(0, ncol = kDimensionOfObservationspace +1 , nrow = kNumberOfTimesteps)
for (i in 1:kNumberOfTimesteps) {
observation[i,] <-c(time[i], observation.matrix %*% c(state1.true[i], state2.true[i]) )
}
colnames.temp <- c("t" ,"y1", "y2")
dataframe.true <- as.data.frame(observation)
colnames(dataframe.true) <- colnames.temp
head(dataframe.true)
#----------------------------------------------
# DEFINE COST FUNCTIONAL --------------------
Regularization <- function(w) {
lasso <- 0
ridge <- 0
for (i in 1:length(w)) {
lasso = lasso + abs(w[i])
ridge = ridge + abs(w[i])**2
}
lasso = kAlpha1 * lasso
ridge = 1./2. * kAlpha2 * ridge
}
TotalCost <- function(w, data) {
cost.temp <- 0
for (i in 1:kNumberOfTimesteps) {
cost.temp = cost.temp + (ObservationUnfit(w,data[,"t"])[i,1]-data[i,"y1"] )**2 +
(ObservationUnfit(w,data[,"t"])[i,2] - data[i,"y2"])**2 + Regularization(w)
}
return( cost.temp )
}
#----------------------------------------------
# Finde optimal w by randomly varying w
# this should work since Regularization(w) is convex
w.initial <- matrix(0, nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) ) )
temp <- matrix(runif(6,0,1),3,2)
Optimize <- function(w.initial, data) {
#initial cost
cost.initial <- TotalCost(w.initial, data)
#define Algorithm to find an appropriate w
w.process <- w.initial
cost.process <- cost.initial
for (i in 1:kNumberOfRandomsteps) {
dw = matrix(runif(6,-0.5,0.5), nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) ) )
if(TotalCost(w.process + dw, data) < cost.process) {
w.process = w.process + dw
cost.process = TotalCost(w.process,data)
}
}
print("w Matrix")
print(w.process)
print("costs")
print(cost.process)
return(w.process)
}
w.test <- Optimize(w.initial, dataframe.true)
#Einfaches Beispiel zur lasso und ridge Regularisierung
# DEFINE SOME CONSTANTS
kDimensionOfStatespace <- 2
kDimensionOfObservationspace <-2
# time interval
kTInitial <- 0
kTFinal   <- 10
kNumberOfTimesteps <- 100
# regularisation parameters
# 1 = lasso, 2 = ridge
kAlpha1 <- 2.0
kAlpha2 <- 2.0
# noise amplitude
kNoiseAmplitude <- 0.1
kNumberOfRandomsteps <- 300
# DEFINE A TRUE SYSTEM -----------------------
# state evolution in time
State1True <- function(t) {
return( 3 * t )
}
State2True <- function(t) {
return( 5 * t**2 )
}
# define outputmatrix
observation.matrix <- matrix(0,  nrow = kDimensionOfStatespace, ncol = kDimensionOfObservationspace )
observation.matrix[1,1] <- 1
observation.matrix[2,2] <- 1
# define timesequence
time <- seq( kTInitial, kTFinal, length.out = kNumberOfTimesteps)
#----------------------------------------------
# DEFINE AN UNFIT SYSTEM ---------------------
# w is kDimensionOfStatespace x number of functions
# define the set of possibe functions
VectorOfFunctions <- function(t) {
return(c(t, t**2, t**3))
}
StateUnfit <- function(w,t) {
return( w %*% VectorOfFunctions(t) )
}
ObservationUnfit <- function(w,t) {
output <- matrix(0, ncol = kDimensionOfObservationspace, nrow = length(t))
for (i in 1:length(t)) {
output[i,] <- observation.matrix %*% StateUnfit(w,t[i])
}
return(output)
}
#----------------------------------------------
# CREATE MEASURED DATA -----------------------
noise.state1.true = runif( kNumberOfTimesteps, -kNoiseAmplitude, kNoiseAmplitude)
noise.state2.true = runif( kNumberOfTimesteps, -kNoiseAmplitude, kNoiseAmplitude)
# evolution of states in time
state1.true <- sapply(time, State1True)
state2.true <- sapply(time, State2True)
# compute observation = (time, y1, y2, ...)
observation <- matrix(0, ncol = kDimensionOfObservationspace +1 , nrow = kNumberOfTimesteps)
for (i in 1:kNumberOfTimesteps) {
observation[i,] <-c(time[i], observation.matrix %*% c(state1.true[i], state2.true[i]) )
}
colnames.temp <- c("t" ,"y1", "y2")
dataframe.true <- as.data.frame(observation)
colnames(dataframe.true) <- colnames.temp
head(dataframe.true)
#----------------------------------------------
# DEFINE COST FUNCTIONAL --------------------
Regularization <- function(w) {
lasso <- 0
ridge <- 0
for (i in 1:length(w)) {
lasso = lasso + abs(w[i])
ridge = ridge + abs(w[i])**2
}
lasso = kAlpha1 * lasso
ridge = 1./2. * kAlpha2 * ridge
}
TotalCost <- function(w, data) {
cost.temp <- 0
for (i in 1:kNumberOfTimesteps) {
cost.temp = cost.temp + (ObservationUnfit(w,data[,"t"])[i,1]-data[i,"y1"] )**2 +
(ObservationUnfit(w,data[,"t"])[i,2] - data[i,"y2"])**2 + Regularization(w)
}
return( cost.temp )
}
#----------------------------------------------
# Finde optimal w by randomly varying w
# this should work since Regularization(w) is convex
w.initial <- matrix(0, nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) ) )
temp <- matrix(runif(6,0,1),3,2)
Optimize <- function(w.initial, data) {
#initial cost
cost.initial <- TotalCost(w.initial, data)
#define Algorithm to find an appropriate w
w.process <- w.initial
cost.process <- cost.initial
for (i in 1:kNumberOfRandomsteps) {
dw = matrix(runif(6,-0.5,0.5), nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) ) )
if(TotalCost(w.process + dw, data) < cost.process) {
w.process = w.process + dw
cost.process = TotalCost(w.process,data)
}
}
print("w Matrix")
print(w.process)
print("costs")
print(cost.process)
return(w.process)
}
w.test <- Optimize(w.initial, dataframe.true)
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
w.temp <- matrix(c(3,0,0,5,0,0), 2,3)
Optimize(w.temp,dataframe.true)
matrix(c(1,1,1,1),2,2) * matrix(c(1,2,3,4),2,2)
matrix(c(1,1,3,1),2,2) * matrix(c(1,2,3,4),2,2)
PreOptimize <- function(upperbound, lowerbound) {
cost.temp <- TotalCost( lowerbound, dataframe.true)
step.index  <- matrix(0 , nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) )  )
step.length <- matrix(0 , nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) )  )
for ( i in 1:length(step.length)) {
step.length[i] = (upperbound[i]-lowerbound[i]) / kNumberOfPreOptimizationsteps
}
for (i in 1:length(step.index)) {
for (j in 1:kNumberOfPreOptimizationsteps) {
dindex <- matrix(0, nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) )  )
dindex[i,j] <- 1
cost.temp.test <- TotlaCost(lowerbound + (step.index + dindex) * step.length, dataframe.true
if (cost.temp.test < cost.temp){
cost.temp <- cost.temp.test
step.index <- step.index + dindex
}
}
}
}
upperbound <- matrix(c( 10, 10, 10, 10, 10, 10) , nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) )  )
lowerbound <- matrix(c(-10,-10,-10,-10,-10,-10) , nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) )  )
w.test <- Optimize(w.initial, dataframe.true)
cost.temp <- TotalCost( lowerbound, dataframe.true)
step.index  <- matrix(0 , nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) )  )
step.length <- matrix(0 , nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) )  )
for ( i in 1:length(step.length)) {
step.length[i] = (upperbound[i]-lowerbound[i]) / kNumberOfPreOptimizationsteps
}
for (i in 1:length(step.index)) {
for (j in 1:kNumberOfPreOptimizationsteps) {
dindex <- matrix(0, nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) )  )
dindex[i,j] <- 1
cost.temp.test <- TotlaCost(lowerbound + (step.index + dindex) * step.length, dataframe.true
if (cost.temp.test < cost.temp){
cost.temp <- cost.temp.test
step.index <- step.index + dindex
}
}
}
}
upperbound <- matrix(c( 10, 10, 10, 10, 10, 10) , nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) )  )
lowerbound <- matrix(c(-10,-10,-10,-10,-10,-10) , nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) )  )
w.test <- Optimize(w.initial, dataframe.true)
PreOptimize <- function(upperbound, lowerbound) {
cost.temp <- TotalCost( lowerbound, dataframe.true)
step.index  <- matrix(0 , nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) )  )
step.length <- matrix(0 , nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) )  )
for ( i in 1:length(step.length)) {
step.length[i] = (upperbound[i]-lowerbound[i]) / kNumberOfPreOptimizationsteps
}
for (i in 1:length(step.index)) {
for (j in 1:kNumberOfPreOptimizationsteps) {
dindex <- matrix(0, nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) )  )
dindex[i,j] <- 1
cost.temp.test <- TotlaCost(lowerbound + (step.index + dindex) * step.length, dataframe.true)
if (cost.temp.test < cost.temp){
cost.temp <- cost.temp.test
step.index <- step.index + dindex
}
}
}
}
upperbound <- matrix(c( 10, 10, 10, 10, 10, 10) , nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) )  )
lowerbound <- matrix(c(-10,-10,-10,-10,-10,-10) , nrow = kDimensionOfStatespace, ncol = length(VectorOfFunctions(0) )  )
source('~/R/OptimalControl/ElasticNet_regularization/main.R', echo=TRUE)
